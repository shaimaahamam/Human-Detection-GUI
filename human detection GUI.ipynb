{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "bitmap \"D:\\senior project\\GUI\\images\\iconn.ico\" not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\senior project\\GUI\\image GUI.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m root\u001b[39m.\u001b[39mresizable(width\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, height\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m root\u001b[39m.\u001b[39mconfigure(background\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m#abadb0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m root\u001b[39m.\u001b[39;49miconbitmap(\u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39msenior project\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mGUI\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mimages\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39miconn.ico\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m labelT \u001b[39m=\u001b[39m tk\u001b[39m.\u001b[39mLabel(root, text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  Autonomous Underwater Vehicle extract the bodies from underwater to the beach  \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m bg \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m#4b8ae3\u001b[39m\u001b[39m'\u001b[39m , fg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m'\u001b[39m ,font\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTimes New Roman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mitalic\u001b[39m\u001b[39m\"\u001b[39m) )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/senior%20project/GUI/image%20GUI.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m labelT\u001b[39m.\u001b[39mplace(x \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m , y \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Intel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:2109\u001b[0m, in \u001b[0;36mWm.wm_iconbitmap\u001b[1;34m(self, bitmap, default)\u001b[0m\n\u001b[0;32m   2107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtk\u001b[39m.\u001b[39mcall(\u001b[39m'\u001b[39m\u001b[39mwm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39miconbitmap\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_w, \u001b[39m'\u001b[39m\u001b[39m-default\u001b[39m\u001b[39m'\u001b[39m, default)\n\u001b[0;32m   2108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtk\u001b[39m.\u001b[39;49mcall(\u001b[39m'\u001b[39;49m\u001b[39mwm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39miconbitmap\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_w, bitmap)\n",
      "\u001b[1;31mTclError\u001b[0m: bitmap \"D:\\senior project\\GUI\\images\\iconn.ico\" not defined"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image , ImageTk\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import importlib.util\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# إنشاء النافذة الرئيسية\n",
    "root = tk.Tk()\n",
    "root.title(\"Underwater Human detection\")\n",
    "screen_width = root.winfo_screenwidth() \n",
    "screen_height = root.winfo_screenheight() \n",
    "root.geometry(f\"{screen_width}x{screen_height}\" )\n",
    "root.resizable(width=False, height=False)\n",
    "root.configure(background=\"#abadb0\")\n",
    "root.iconbitmap(\"D:\\\\senior project\\\\GUI\\\\images\\\\iconn.ico\")\n",
    "\n",
    "\n",
    "labelT = tk.Label(root, text=\"  Autonomous Underwater Vehicle extract the bodies from underwater to the beach  \",\n",
    "bg ='#4b8ae3' , fg = 'white' ,font=(\"Times New Roman\", 30, \"italic\") )\n",
    "labelT.place(x = 0 , y = 0)\n",
    "labelT.pack()\n",
    "\n",
    "\n",
    "\n",
    "#frame0\n",
    "frame0 = tk.Frame(root, height=665 , width = 1335 )\n",
    "frame0.pack(side=\"top\", padx=10, pady = 10)\n",
    "\n",
    "\n",
    "\n",
    "#frame 1\n",
    "frame1 = tk.LabelFrame(root, text=\"Unlabeled Image\", height=400 , width = 400 , bg = '#4b8ae3')\n",
    "frame1.pack(side=\"left\", expand=True, padx=20, pady=20)\n",
    "frame1.place(x = 230 , y = 100)\n",
    "\n",
    "#frame2\n",
    "frame2 = tk.LabelFrame(root, text=\"labeled Image\", height=400 , width = 410 , bg = '#4b8ae3')\n",
    "frame2.pack(side=\"left\", expand=True, padx=20, pady=20)\n",
    "frame2.place(x = 770 , y = 100)\n",
    "\n",
    "\n",
    "# functions \n",
    "\n",
    "#fun1\n",
    "def open_file_dialog():\n",
    "    global input_image_path\n",
    "    input_image_path = filedialog.askopenfilename(initialdir = \"/\",title = \"Select Image File\",filetypes = ((\"JPEG files\",\"*.jpg\"),(\"PNG files\",\"*.png\"),(\"All Files\",\"*.*\")))\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    input_image = cv2.resize(input_image, (400, 400))\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    input_image = ImageTk.PhotoImage(image=input_image)\n",
    "    img_label = tk.Label(frame1)\n",
    "    img_label.configure(image=input_image)\n",
    "    img_label.image = input_image\n",
    "    img_label.pack()  \n",
    "    \n",
    "    \n",
    "    return input_image_path\n",
    "\n",
    "pathh = open_file_dialog()   \n",
    "\n",
    "# button 1\n",
    "select_image_btn = tk.Button(frame0, text=\" Load Image \", bg = '#4b8ae3' , fg = 'white', font=(\"Times New Roman\", 12, \"bold\"),\n",
    "command = open_file_dialog )\n",
    "select_image_btn.pack(pady=10)\n",
    "select_image_btn.place(x = 520 , y = 500)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#func 2\n",
    "\n",
    "def tflite_detect_images(modelpath = 'D:\\\\senior project\\\\last inshaa allah\\\\detect.tflite' , imgpath = pathh,\n",
    " lblpath = 'D:\\\\senior project\\\\last inshaa allah\\\\label.txt' ,savepath = 'D:\\\\senior project\\\\applicable data\\\\test', min_conf=0.75):\n",
    "\n",
    "  # Grab filenames of all images in test folder\n",
    "  #images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
    "\n",
    "  # Load the label map into memory\n",
    "  with open(lblpath, 'r') as f:\n",
    "      labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "  # Load the Tensorflow Lite model into memory\n",
    "  interpreter = Interpreter(model_path=modelpath)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  # Get model details\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "  height = input_details[0]['shape'][1]\n",
    "  width = input_details[0]['shape'][2]\n",
    "\n",
    "  float_input = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "  input_mean = 127.5\n",
    "  input_std = 127.5\n",
    "\n",
    "  \n",
    "  image = cv2.imread(pathh)\n",
    "  imH, imW, _ = image.shape \n",
    "  image_resized = cv2.resize(image, (width, height))\n",
    "  input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "  if float_input:\n",
    "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "      # Perform the actual detection by running the model with the image as input\n",
    "  interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "  interpreter.invoke()\n",
    "\n",
    "      # Retrieve detection results\n",
    "  boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
    "  classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
    "  scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
    "\n",
    "  detections = []\n",
    "\n",
    "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "  for i in range(len(scores)):\n",
    "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
    "\n",
    "              # Get bounding box coordinates and draw box\n",
    "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "              \n",
    "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "              # Draw label\n",
    "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
    "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
    "\n",
    "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
    "\n",
    "      \n",
    "      \n",
    "  \n",
    "  \n",
    "  patho = 'D:\\\\senior project\\\\applicable data\\\\test\\\\image.jpg'\n",
    "  cv2.imwrite(patho, image)\n",
    "\n",
    "  return patho\n",
    "\n",
    "lblpath = tflite_detect_images()\n",
    "\n",
    "\n",
    "\n",
    "# button 2\n",
    "select_image_btn2 = tk.Button(frame0, text=\"Apply Model\", bg = '#4b8ae3' , fg= 'white' , font=(\"Times New Roman\", 12, \"bold\"),\n",
    "command = tflite_detect_images )\n",
    "select_image_btn2.pack(pady=10)\n",
    "select_image_btn2.place(x = 650 , y = 500)\n",
    "\n",
    "\n",
    "def show_label(path = lblpath):\n",
    "  \n",
    "    input_image = cv2.imread(lblpath)\n",
    "    input_image = cv2.resize(input_image, (400, 400))\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
    "    input_image = Image.fromarray(input_image)\n",
    "    input_image = ImageTk.PhotoImage(image=input_image)\n",
    "    img_label2 = tk.Label(frame2)\n",
    "    img_label2.configure(image=input_image)\n",
    "    img_label2.image = input_image\n",
    "    img_label2.pack()  \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# button 3 \n",
    "select_image_btn3 = tk.Button(frame0, text=\" Show Label \" , bg = '#4b8ae3', fg = 'white' ,font=(\"Times New Roman\", 12, \"bold\"),\n",
    " command = show_label )\n",
    "select_image_btn3.pack(pady=10)\n",
    "select_image_btn3.place(x = 780 , y = 500)\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
